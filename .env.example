# Environment Configuration

# Port for Express server
PORT=3000

# LLM API Configuration
# Replace with your actual Gemini API endpoint (e.g., https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent)
GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent
GEMINI_API_KEY=aabbccddeeffgghhiijjkkllmmnnooppqqrrssttuuvvwwxxyyzz

# File Upload Configuration
MAX_FILE_SIZE_MB=10

# Node Environment
NODE_ENV=development

# LLM Generation Configuration
LLM_TEMPERATURE=0.1
LLM_MAX_OUTPUT_TOKENS=16384
LLM_TIMEOUT_MS=120000

# CV Improvement Suggestions (true to include detailed improvement advice, false to skip)
CV_IMPROVEMENT_SUGGESTIONS_ENABLED=true