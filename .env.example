# Environment Configuration

# Port for Express server
PORT=3000

# LLM API Configuration
# Replace with your actual Gemini API endpoint (e.g., https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent)
GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent
GEMINI_API_KEY=aabbccddeeffgghhiijjkkllmmnnooppqqrrssttuuvvwwxxyyzz

# File Upload Configuration
MAX_FILE_SIZE_MB=10

# Node Environment
NODE_ENV=development

# LLM Generation Configuration
LLM_TEMPERATURE=0.1
LLM_MAX_OUTPUT_TOKENS=16384
LLM_TIMEOUT_MS=120000

# CV Improvement Suggestions (true to include detailed improvement advice, false to skip)
CV_IMPROVEMENT_SUGGESTIONS_ENABLED=true

WEBHOOK_URL=http://127.0.0.1:8000/api/webhook/cv-result

NODE_SERVICE_SECRET=1234567890